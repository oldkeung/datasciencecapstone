---
title: "Untitled"
author: "William Lai"
date: "10 April 2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(cache = TRUE)
```

## 1. Introduciton

```{r, message = FALSE, warning = FALSE}
library(quanteda)
library(markovchain)
library(textcat)
```

## 2. Getting and Cleansing Data

```{r, cache=TRUE}
url <- "https://d396qusza40orc.cloudfront.net/dsscapstone/dataset/Coursera-SwiftKey.zip"
zipfile <- "Coursera-SwiftKey.zip"
```

```{r "Download Data", cache=TRUE}
#download.file(url, destfile = zipfile)
#unzip(zipfile, exdir = ".")
```

```{r "Load Data", cache=TRUE}
blogConn <- file("final/en_US/en_US.blogs.txt", "r") 
newsConn <- file("final/en_US/en_US.news.txt", "r") 
twitterConn <- file("final/en_US/en_US.twitter.txt", "r") 

blog <- readLines(blogConn)
news <- readLines(newsConn)
twitter <- readLines(twitterConn)

close(blogConn)
close(newsConn)
close(twitterConn)
```

```{r Sampling}
set.seed(88888)

blogCount <- length(blog)
newsCount <- length(news)
twitterCount <- length(twitter)

blogSample <- blog[rbinom(blogCount, 1, 0.05) == 1]
newsSample <- news[rbinom(newsCount, 1, 0.05) == 1]
twitterSample <- twitter[rbinom(twitterCount, 1, 0.05) == 1]
```

### 2.1 Tokenization 

```{r}
all <- c(blogSample, newsSample, twitterSample)

allCorpus <- corpus(all)

samplesdfm <- dfm(allCorpus, toLower = TRUE, removeNumbers = TRUE, removePunct = TRUE, removeTwitter = TRUE, ignoredFeatures = stopwords("english"), stem = TRUE)

toks <- tokens(all, remove_punct = TRUE)

unigram <- tokens_ngrams(toks, n = 1)
bigram <- tokens_ngrams(toks, n = 2)
trigram <- tokens_ngrams(toks, n = 3)
quadgram <- tokens_ngrams(toks, n = 4)

head(bigram[[1]], 10)
head(trigram[[1]], 10)
head(quadgram[[1]], 10)

unigramdfm <- dfm(unigram)
bigramdfm <- dfm(bigram)
trigramdfm <- dfm(trigram)
quadgramdfm <- dfm(quadgram)
#removefeatures(bigramdfm, "in")
```

### 2.2 Profanity filtering

```{r, cache=TRUE}
badWordUrl <- "https://www.freewebheaders.com/wordpress/wp-content/uploads/full-list-of-bad-words-text-file_2018_03_26_26.zip"
badWordzipfile <- "full-list-of-bad-words-text-file.zip"
```

```{r "Download Bad Words Data", cache=TRUE}
download.file(badWordUrl, destfile = badWordzipfile)
unzip(badWordzipfile, exdir = ".")
```

```{r, cache=TRUE}
badWordConn <- file("full-list-of-bad-words-text-file_2018_03_26.txt", "r") 

badWord <- readLines(badWordConn, 1000)

close(badWordConn)
```

### 3 Data Summary

1. Word Count

Data Source | Word Counts
---
Blog | `r #ntoken(blogSample)`
News | `r #ntoken(newsSample)`
Twitter | `r #ntoken(twitterSample)`

2. Line Count

3. Features

```{r}
#topfeatures(bigramdfm, 10)

textplot_wordcloud(unigramdfm, max_words = 100)
textplot_wordcloud(bigramdfm, max_words = 30)
textplot_wordcloud(trigramdfm, max_words = 30)
textplot_wordcloud(quadgramdfm, max_words = 30)
```

### 4 Approach